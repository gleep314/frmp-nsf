%!TEX root = project_description.tex

\section{Temporary Place for CRN Examples}
\todo{Remove this section once it isn't needed (or move it elsewhere).}
This section is for generating motivating molecular programming examples that relate to this project.
(So this section will eventually need to be removed.)

\subsection{Hailstone Function}
Suppose we'd like to create a stochastic CRN that, given \( n \) initial molecules of type \( X \), will eventually produce \( H(n) \) molecules of type \( Y \) where \( H(n) \) is the Hailstone function:
\begin{equation}
    H(n) = \begin{cases}
        n/2, &\text{ if }n\text{ is even}\\
        3n+1, &\text{ if }n\text{ is odd}
    \end{cases}
\end{equation}
Computing this function with an SCRN can be broken into the following parts: (1) checking if \( n \) is divisible by two, (2) dividing \( n \) by two, (3) multiplying \( n \) by three, (4) incrementing a value by 1, and (5) multiplexing the output so that either \( n/2 \) or \( 3n+1 \) output depending on the result of the parity check.
Below is the SCRN that successfully computes this function:
\begin{align}
    X &\goesto{} A_\text{odd} + B + C + D\label{eq:hailstone_split}\\
    A_\text{odd} + A_\text{odd} &\goesto{} A_\text{even}\label{eq:hailstone_parity1}\\
    A_\text{even} + A_\text{even} &\goesto{} A_\text{even}\label{eq:hailstone_parity2}\\
    A_\text{odd} + A_\text{even} &\goesto{} A_\text{odd}\label{eq:hailstone_parity3}\\
    2 B &\goesto{} Y_1\label{eq:halstone_n2}\\
    C &\goesto{} 3Y_2\label{eq:halstone_3n}\\
    A_\text{even} + Y_1 &\goesto{} A_\text{even} + Y + \widehat{Y}_1\label{eq:halstone_mux1}\\
    A_\text{odd} + Y_2 &\goesto{} A_\text{odd} + Y + \widehat{Y}_2\label{eq:halstone_mux2}\\
    A_\text{odd} + Y + \widehat{Y}_1 &\goesto{} A_\text{odd} + Y_1\label{eq:halstone_rev1}\\
    A_\text{even} + Y + \widehat{Y}_2 &\goesto{} A_\text{even} + Y_2\label{eq:halstone_rev2}\\
    2 D &\goesto{} D\label{eq:halstone_1}\\
    D + \widehat{D} &\goesto{} D\\
    2Y + 2\widehat{D} &\goesto{} Y + \widehat{D}\\
    A_\text{odd} + D &\goesto{} A_\text{odd} + Y + \widehat{D}\\
    A_\text{even} + Y + \widehat{D} &\goesto{} A_\text{even} + D\label{eq:halstone_1end}
\end{align}
In the above SCRN, reaction~\eqref{eq:hailstone_split} simply copies the number of \( X \)'s into four species that can be used to compute all four components necessary to finish the algorithm in parallel.
Reactions~\eqref{eq:hailstone_parity1}--\eqref{eq:hailstone_parity3} compute the Boolean parity function: if \( n \) is even, then the number of \( A_\text{even} \)'s converges to 1 and the number of \( A_\text{odd} \)'s converges to 0; likewise, if \( n \) is odd, then \( A_\text{odd} \) goes to 1 and \( A_\text{even} \) goes to 0.
Reaction~\eqref{eq:halstone_n2} computes \( n/2 \) and stores the answer in \( Y_1 \).
Reaction~\eqref{eq:halstone_3n} computes \( 3n \) and stores the answer in \( Y_2 \).
Reactions~\eqref{eq:halstone_mux1}--\eqref{eq:halstone_mux2} uses the result of the parity check and copies \( Y_1 \) into \( Y \) if \( A_\text{even} \) exists and \( Y_2 \) is copied if \( A_\text{odd} \) exists.
These multiplexer reactions can be reversed using reactions~\eqref{eq:halstone_rev1}--\eqref{eq:halstone_rev2} so that any values copied over prematurely can be undone once the parity computation finishes.
Finally, reactions~\eqref{eq:halstone_1}--\eqref{eq:halstone_1end} are responsible for computing the number 1 and copying it into \( Y \) if \( n \) is odd.

\subsection{Maximum Function}
There has been some recent research on \emph{composable} SCRNs, \ie, SCRNs that can be modularly combined with provably no problems occurring~\cite{doty19}.
It is well-known that these SCRNs must be \emph{output-oblivious}, \ie, the number of output molecules must be generated in a monotonically increasing fashion.
It is also well-known that computing the \emph{maximum} of two numbers cannot be computed by an SCRN in an output-oblivious fashion.

For example, below is an implementation of maximum with an SCRN:
\begin{align}
    X_1 &\goesto{} A_1 + Y\\
    X_2 &\goesto{} A_2 + Y\\
    A_1 + A_2 &\goesto{} B\\
    Y + B &\goesto{} \emptyset
\end{align}
The idea behind the above solution is that we can write the maximum of two numbers \( n_1, n_2 \) as:
\[
    \text{max}(n_1, n_2) = n_1 + n_2 - \text{min}(n_1, n_2).
\]
We compute the maximum function in this way by first computing the sum of \( X_1 \) and \( X_2 \) and storing the result in \( Y \), and then later subtracting from \( Y \) the minimum of \( X_1 \) and \( X_2 \) (this is computed with the \( A_1 + A_2 \goesto{} B \) reaction.)

Notice that this is NOT computing \( Y \) in a monotonically increasing fashion.
We first compute the sum (which could overshoot the maximum by quite a lot), and later we will decrease the total number of \( Y \)'s using the \( Y + B \goesto{} \emptyset \) reaction.

\subsection{Signal Multiplexer}
CRNs don't need to be considered machines that take in natural numbers and output natural numbers.
In fact, they are more naturally a \emph{signal processor} and can receive streams of molecules, \ie, a time-varying signal of molecules, and output a time-varying signal of molecules in response.

As a simple case of this, consider a deterministic CRN implementation of a multiplexer that receives two signals as input through species \( X_1 \) and \( X_2 \) along with a switch molecule \( S \).
If \( S \) is close to 1, then we want to have the output \( Y \) be identical to the signal provided through \( X_1 \), and if \( S \) is close to 0, then we want to have \( Y \) be identical to the signal \( X_2 \).
This cannot be done with perfect accuracy, but here is an approach:
\begin{align}
    S + X_1 &\goesto{k} S + X_1 + Y\\
    \overline{S} + X_2 &\goesto{k} \overline{S} + X_2 + Y\\
    Y &\goesto{k} \emptyset.
\end{align}
This approximates what we want because the ODE for \( Y \) is:
\begin{equation}
    \frac{dy}{dt} = k\left[s(t)x_1(t) + \overline{s}(t)x_2(t) - y(t)\right].
\end{equation}
Now, if \( s(t) + \overline{s}(t) = 1 \) for all \( t\in[0,\infty) \), then when \( S \) is close to 1, then \( \overline{S} \) is close to 0 and vice versa.
Thus, the above equation is really equal to one of the following:
\begin{align}
    \frac{dy}{dt} = k\left[x_1(t) - y(t)\right]\\
    \frac{dy}{dt} = k\left[x_2(t) - y(t)\right]
\end{align}
Thus, if \( S \) is high, then \( Y \) is ``chasing'' the concentration of \( X_1 \), and if \( S \) is low, then \( Y \) is ``chasing'' \( X_2 \).
If \( k \) is sufficiently large, then \( Y \) is a great approximation of the multiplexer we desire.

The technique of splitting the signal \( S \) into two is called \textbf{dual-rail representation} which allows us to use the presence of \( \overline{S} \) to have the same meaning as the absence of \( S \).

\subsection{Use of an LTL-like Temporal Logic}
Many of the above examples have a \emph{specification} or \emph{requirement} that can easily be written in an LTL like language.
For example, the hailstone requirement would simply be the following:
\begin{equation}\label{eq:hailstone_ltl}
    \Diamond\Box\left[y = H(x(0))\right].
\end{equation}
Recall that \( \Diamond\Phi \) is the ``future'' operator and means that eventually \( \Phi \) becomes true and that \( \Box\Psi \) is the ``globally'' operator and means that \( \Psi \) must always be true.
Therefore, equation~\eqref{eq:hailstone_ltl} means: ``eventually the number of \( Y \)'s will be equal to \( H(x_0) \) forever,'' which is exactly what we want.

Similarly, the maximum function can be written in an LTL-like language like this:
\begin{equation}\label{eq:max_ltl}
    \Diamond\Box[y=\max(x_1(0),x_2(0))]
\end{equation}

One thing that should be noted, is that most interesting SCRNs only \emph{probabilistically} converge to the correct answer.
SCRNs can only compute the semi-linear functions with probability 1, but they are Turing universal if you allow for any \( \epsilon > 0 \) probability of failure.
Therefore, to quantify most SCRN requirements, such as computing \( 2^n \), the requirement would need to be specified probabilistically such as:
\begin{equation}
    \mathcal{P}_{\ge1-\epsilon}\Diamond\Box[y=2^{x(0)}]
\end{equation}
which says that with probability \( 1 - \epsilon \) the LTL formula must be true.

There are probabilistic logics that exist, such as \emph{probabalistic computational tree logic} (\emph{PCTL}) and \emph{continuous stochastic logic} (\emph{CSL}), however, these formulae are \emph{state} formulae instead of \emph{path} formulae like LTL.
Therefore, we expect using a probabilistic version LTL will be more useful.

For DCRNs, there is a temporal logical called \emph{signal temporal logic} which is a continuous-time, continuous-space, variant of LTL.
It specifies precise relationships between the input signals and output signals.
For example, we might write an STL formula for the DCRN signal processor specification mentioned above with:
\begin{equation}
    \Box[(s=1)\implies(y=x_1)]\land\Box[(s=0)\implies(y=x_2)],
\end{equation}
which means that globally, if \( s(t)=1 \) then the concentration of \( y(t) \) is equal to \( x_1(t) \), and similarly if \( s(t) = 1 \), then the concentration of \( y(t) \) is equal to \( x_2(t) \).
This is a VERY strict requirement because \( Y \) must \emph{exactly} equal the corresponding concentration of the input.
(It is easy to prove this is impossible for DCRNs.)
Thus, it would be better if we had a way of \emph{approximately} satisfying an STL formula.
For example, if we look at the solution to the system of ODEs that corresponds to the DCRN given, what we really want is to compute a \emph{distance measure} of how close we are to satisfying the STL formula and then say we \emph{\(\epsilon\)}-approximately satisfy it if the measure is within \emph{\(\epsilon\)}.

We have other previous results that use continuous stochastic logic (CSL) to specify requirements and then \emph{formally verify} their correctness in model checkers like PRISM.
In particular, these papers:~\cite{cEHKLLL14,tosem19}.
We specify the high-level requirements of a ``watchdog timer'' in CSL, refine them into smaller requirements, prove that the sub-goals imply the super-goals, and then use PRISM to verify the leaf goals of the requirements tree.
